{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this notebook about?\n",
    "\n",
    "In this notebook, we will learning about PyTorch modules and the great functionalities they provide. Later on, we'll create a small a multilayer perceptron to perform image classification on MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# execute only if you're using Google Colab\n",
    "!wget -q https://raw.githubusercontent.com/ahug/amld-pytorch-workshop/master/binder/requirements.txt -O requirements.txt\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, there are many predefined layer like Convolutions, RNN, Pooling, Linear, etc.\n",
    "\n",
    "These functions are wrapped in **modules** and inherit from the **torch.nn.Module** base class.\n",
    "\n",
    "When designing a custom model in PyTorch, you should follow this strategy and derive your class from **torch.nn.Module**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base class for all neural network modules.\n",
      "\n",
      "    Your models should also subclass this class.\n",
      "\n",
      "    Modules can also contain other Modules, allowing to nest them in\n",
      "    a tree structure. You can assign the submodules as regular attributes::\n",
      "\n",
      "        import torch.nn as nn\n",
      "        import torch.nn.functional as F\n",
      "\n",
      "        class Model(nn.Module):\n",
      "            def __init__(self):\n",
      "                super(Model, self).__init__()\n",
      "                self.conv1 = nn.Conv2d(1, 20, 5)\n",
      "                self.conv2 = nn.Conv2d(20, 20, 5)\n",
      "\n",
      "            def forward(self, x):\n",
      "                x = F.relu(self.conv1(x))\n",
      "                return F.relu(self.conv2(x))\n",
      "\n",
      "    Submodules assigned in this way will be registered, and will have their\n",
      "    parameters converted too when you call :meth:`to`, etc.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Module.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules are doing a lot of \"magic\" under the hood.\n",
    "\n",
    "- It registers all the parameters of your model.\n",
    "- It simplifies the saving/loading of your model.\n",
    "- It provides helper functions to reset/freeze/update the gradients.\n",
    "- It provides helper functions to put all parameters on a device (GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a torch.nn.Parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Parameter is a Tensor with `requires_grad` to `True` by default, and which is automatically added to the list of parameters when used within a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the documentation ([torch.nn.Paramter](https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A kind of Tensor that is to be considered a module parameter.\n",
      "\n",
      "    Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
      "    very special property when used with :class:`Module` s - when they're\n",
      "    assigned as Module attributes they are automatically added to the list of\n",
      "    its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
      "    Assigning a Tensor doesn't have such effect. This is because one might\n",
      "    want to cache some temporary state, like last hidden state of the RNN, in\n",
      "    the model. If there was no such class as :class:`Parameter`, these\n",
      "    temporaries would get registered too.\n",
      "\n",
      "    Arguments:\n",
      "        data (Tensor): parameter tensor.\n",
      "        requires_grad (bool, optional): if the parameter requires gradient. See\n",
      "            :ref:`excluding-subgraphs` for more details. Default: `True`\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Parameter.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.1103, -0.1596, -0.1015],\n",
      "         [-0.0955,  0.1123, -0.0582],\n",
      "         [-0.1182,  0.0353,  0.0349],\n",
      "         [-0.0114, -0.0519,  0.1407],\n",
      "         [ 0.1191, -0.1665,  0.0562],\n",
      "         [-0.0463,  0.0737, -0.0403],\n",
      "         [ 0.0940,  0.1121,  0.0919],\n",
      "         [ 0.0727,  0.0484,  0.0477],\n",
      "         [-0.1394,  0.1319, -0.0180],\n",
      "         [ 0.0369,  0.1783, -0.0890]],\n",
      "\n",
      "        [[ 0.0941,  0.1787, -0.1786],\n",
      "         [ 0.1730, -0.0338,  0.1099],\n",
      "         [-0.0972,  0.1375, -0.1051],\n",
      "         [-0.1621, -0.1433, -0.1345],\n",
      "         [ 0.1595, -0.0838, -0.0313],\n",
      "         [-0.1148,  0.1254,  0.1246],\n",
      "         [-0.0575,  0.1522, -0.1141],\n",
      "         [ 0.1189,  0.1175,  0.0168],\n",
      "         [ 0.0614,  0.0042, -0.0487],\n",
      "         [-0.0260, -0.0392,  0.0905]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mod = nn.Conv1d(10, 2, 3)\n",
    "print(mod.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very simple example of a module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A module has to implement two functions:\n",
    "\n",
    "- the `__init__` function, where you define all the layers that have learnable parameters. In the `__init__` function, you are just specifying each layer and not how it is connected to others, so it does not need to be in order of execution. Since your model's submodules and parameters are instantiated in the `__init__` function, PyTorch knows that they exist and registers them.  \n",
    "Also, don't forget to always call the `super()` method.  \n",
    "\n",
    "\n",
    "- the `forward` function, which is the method that defines what has to be executed during the forward pass and especially how the layers are connected. This is where you call the layers that you defined inside the `__init__` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple module\n",
    "class MySuperSimpleModule(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MySuperSimpleModule, self).__init__()  # Mandatory call to super\n",
    "        self.linear = nn.Linear(input_size, num_classes)  # Define one Linear layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the print function to list a model's submodules and parameters defined inside `init`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySuperSimpleModule(\n",
      "  (linear): Linear(in_features=20, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MySuperSimpleModule(input_size=20, num_classes=5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use **`model.parameters()`** to get the list of parameters of your model automatically inferred by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.weight :\n",
      " Parameter containing:\n",
      "tensor([[-0.0896,  0.2153,  0.0700, -0.0119, -0.0438,  0.0140,  0.1668, -0.0652,\n",
      "         -0.1482, -0.2235,  0.0974,  0.1524,  0.2233,  0.0591, -0.0934,  0.1632,\n",
      "         -0.1902, -0.1373,  0.0371, -0.0199],\n",
      "        [-0.2025,  0.1954, -0.1059,  0.2122,  0.1804,  0.1338,  0.0847,  0.0297,\n",
      "          0.0786, -0.1775,  0.1276, -0.0137,  0.1283,  0.0400, -0.1175, -0.0048,\n",
      "          0.1317, -0.0340,  0.0383,  0.2141],\n",
      "        [-0.1703, -0.0031, -0.1562, -0.1007, -0.1592, -0.0341,  0.1713, -0.0420,\n",
      "         -0.0757, -0.1681, -0.0446, -0.0009, -0.0136, -0.0735, -0.1329,  0.0546,\n",
      "         -0.0499,  0.0811,  0.2119,  0.1607],\n",
      "        [-0.0268,  0.1423, -0.0188, -0.0128,  0.1567,  0.0234, -0.0020,  0.1162,\n",
      "          0.1943, -0.2042, -0.1274,  0.1762, -0.1992, -0.1799,  0.2153,  0.0147,\n",
      "         -0.1370, -0.2234, -0.0665, -0.1017],\n",
      "        [-0.0425,  0.1930,  0.0375,  0.1401,  0.1810, -0.2007, -0.0250, -0.1288,\n",
      "          0.1601,  0.1801, -0.2003,  0.0459,  0.0686,  0.0261, -0.1564, -0.0412,\n",
      "         -0.2063,  0.2139, -0.1157, -0.1265]], requires_grad=True)\n",
      "linear.bias :\n",
      " Parameter containing:\n",
      "tensor([-0.0076, -0.1748, -0.0510,  0.0416, -0.0890], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():  # Here we use a sligtly different version of the parameters() function\n",
    "    print(name, \":\\n\", p)                 # which also returns the parameter name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This intro to modules used [this medium post](https://medium.com/deeplearningbrasilia/deep-learning-introduction-to-pytorch-5bd39421c84) as a resource."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
